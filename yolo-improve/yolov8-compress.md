# YOLOV8剪枝项目介绍

## 对于群里的剪枝相关问题,我基本都会回复,对于一些剪枝问题,我都会给出建议。  

### 首先剪枝是什么？  
模型剪枝是深度学习中的一种技术，旨在通过减少神经网络中不必要的参数和连接，来优化模型的效率和性能。模型剪枝可以分为结构剪枝和参数剪枝两种类型。  

### 为什么需要剪枝？  
剪枝可以很好地衡量模型轻量化程度与精度的关系,是替换轻量化结构完全没办法比的,比如我模型剪枝可以压缩百分之30的计算量,精度只下降了百分之1,但是你通过换模块来达到压缩百分之30的计算量,一般时间就会变长,因为大部分轻量化模块都是由时间换空间,而且精度还会下降得比较多,但是剪枝可以很好地避免这个问题.

### 目前剪枝项目包含以下剪枝方法：
1. L1 
2. Random 
3. Slim 
4. GroupSlim 
5. GroupNorm 
6. LAMP 
7. GroupSL 
8. GroupReg
9. GroupHessian
10. GroupTaylor

### 其中prune系列还有一些细节：
1. 支持稀疏训练时候可视化BN稀疏程度和数值。
2. 稀疏训练的稀疏系数会进行线性调整，让稀疏训练后期精度更容易回升，更稳定。
3. 支持设定加速比例，模型会进行自动压缩，压缩到指定比例或者达到最大压缩次数后会自动进入finetune。

### 剪枝的一些顾虑
大家关心最多的一个问题就是，我的结构能不能剪之类的，剪枝对模型复杂度的要求比较高，目前剪枝都是基于Torch_Pruning库进行剪枝，prune系列的可以跳过一些不能剪枝的层(某些复杂的结构可能在构建动态图的时候失败,这些就只能换结构)，这个项目会有比较多的示例和视频教程教大家如何去剪自己的结构,注意点在哪里等等。这个剪枝项目是没办法保证所有的结构都能剪，有一定的风险，是否入手请自行考虑！  
[yolov5v7剪枝](https://github.com/z1069614715/objectdetection_script/blob/master/yolo-improve/yolov5v7-light.md)这里面的结构都经过实验是可剪的.

### 那些人群建议入手剪枝
1. 原始的算法精度很高,没办法再提升精度,只能走轻量化路线,这种建议配合一些轻量化模块+剪枝来增加你的工作量和创新度.
2. 需要部署到嵌入式或者手机端等低算力设备,这类本身模型就不能太复杂,而且以轻量化为主,剪枝是非常适合的.
3. 以后需从事深度学习方面的工作,模型轻量化(蒸馏、量化、剪枝)基本是必须要会的技能.

### Yolov8 相关实验 GPU-Device:RTX3090
#### Dataset:VisDrone 30%TrainingData Model:Yolov8n
| model | Parameters | GFLOPs | Model Size | mAP50 | mAP50-95 | Inference Time(bs:32) |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| BaseLine | 3,007,598 | 8.1 | 5.9m | 0.225 | 0.124 | 0.00099s |
| Lamp Exp1 2.0X | 1,513,245(50.3%) | 4.0(50%) | 3.1m(52.5%) | 0.197(-0.018) | 0.106(-0.018) | 0.00075s(75.8%) |
| Lamp Exp2 2.0X | 679,484(22.6%) | 4.0(50%) | 1.5m(25.4%) | 0.231(+0.006) | 0.126(+0.002) | 0.00073s(73.7%) |
| Lamp Exp3 2.5X | 503,959(16.8%) | 3.2(39.5%) | 1.2m(20.3%) | 0.225(0.0) | 0.123(-0.001) | 0.00068s(68.7%) |
| Group-Taylor Exp1 2.0X | 1,093,305(36.4%) | 4.0(50%) | 2.3m(39%) | 0.203(-0.022) | 0.11(-0.014) | 0.00074s(74.8%) |
| Group-Taylor Exp2 2.0X | 1,513,245(50.3%) | 4.0(50%) | 3.1m(52.5%) | 0.196(-0.029) | 0.105(-0.019) | 0.00075s(75.8%) |
| Group-Hessian Exp1 2.0X | 1,436,390(47.8%) | 4.0(50%) | 3.0m(50.8%) | 0.168(-0.057) | 0.0883(-0.041) | 0.00071s(71.7%) |
| Group-Sl Exp1 2.0X | 1,556,422(51.7%) | 4.0(50%) | 3.1m(52.5%) | 0.173(-0.052) | 0.0901(-0.0339) | 0.00066s(66.7%) |
| Group-Slim Exp1 2.0X | 1,113,000(37%) | 4.0(50%) | 2.3m(39%) | 0.201(-0.024) | 0.108(-0.016) | 0.00075s(75.8%) |
| Slim Exp1 2.0X | 932,902(31%) | 4.0(50%) | 2.0m(33.9%) | 0.21(-0.015) | 0.114(-0.01) | 0.00075s(75.8%) |

#### Dataset:VisDrone 30%TrainingData Model:yolov8-Faster-GFPN-P2-EfficientHead
| model | Parameters | GFLOPs | Model Size | mAP50 | mAP50-95 | Inference Time(bs:32) |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| BaseLine | 3,457,400 | 12.1 | 7.2M | 0.241 | 0.133 | 0.00188s |
| Lamp Exp1 2.0X | 903,894(26.1%) | 5.9(48.6%) | 2.3M(32%) | 0.226(-0.015) | 0.127(-0.006) | 0.00150s(83.3%) |
| GroupTaylor Exp1 2.0X | 1,699,046(49.1%) | 5.9(48.6%) | 3.9M(54.2%) | 0.212(-0.029) | 0.115(-0.028) | 0.00142s(75.5%) |
| GroupTaylor Exp2 2.0X | 1,751,941(51%) | 6.0(49.6%) | 4.0M(55.6%) | 0.216(-0.025) | 0.119(-0.024) | 0.00147s(78.2%) |
| GroupHessian Exp1 2.0X | 1,751,941(51%) | 6.0(49.6%) | 2.3M(32%) | 0.214(-0.023) | 0.118(-0.025) | 0.00147s(78.2%) |